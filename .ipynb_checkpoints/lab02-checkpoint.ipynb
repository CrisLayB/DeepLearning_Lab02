{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2\n",
    "## Universidad del Valle de Guatemala <br> Facultas de Ingeniería\n",
    "#### Departamento de Ciencias de la Computación <br> Deep Learning y Sistemas Inteligentes - Sección 20\n",
    "#### Grupo 12  \n",
    "Cristian Laynez, Jeyner Arango"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo de la Red"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de Redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# Cargar la base de datos\n",
    "dataset = pd.read_csv('movie_statistic_dataset.csv')\n",
    "\n",
    "# eliminar las filas con valores faltantes en la columna de destino\n",
    "dataset = dataset.dropna(subset=['Worldwide gross $'])\n",
    "\n",
    "# Indexar 'movie_title'\n",
    "dataset.set_index('movie_title', inplace=True)\n",
    "\n",
    "#runtime_minutes\n",
    "dataset['runtime_minutes'] = dataset['runtime_minutes'].astype(int)\n",
    "\n",
    "#director_name\n",
    "#Es mejor convertir los directores faltantes a NaN (No es un número)\n",
    "dataset['director_name'].replace('-', np.nan, inplace=True)\n",
    "\n",
    "#production_date: AAAA-MM-DD\n",
    "#Como el campo representa una fecha, es mejor transformarlo en características separadas de\n",
    "#año, mes y día. De esta manera, la red neuronal puede capturar mejor los patrones temporales.\n",
    "dataset['production_year'] = pd.to_datetime(dataset['production_date']).dt.year\n",
    "dataset['production_month'] = pd.to_datetime(dataset['production_date']).dt.month\n",
    "dataset['production_day'] = pd.to_datetime(dataset['production_date']).dt.day\n",
    "\n",
    "# botar la columnar original 'production_date' \n",
    "dataset.drop(columns=['production_date'], inplace=True)\n",
    "\n",
    "#genres: varios géneros separados por comas\n",
    "#Podemos usar la codificación one-hot para convertir \n",
    "#los géneros en columnas binarias separadas para cada género.\n",
    "# Convertir genres a columnas binarias utilizando one-hot encoding\n",
    "dataset['genres'].replace(r'\\N', '', inplace=True)\n",
    "genres_list = dataset['genres'].str.get_dummies(sep=',')\n",
    "dataset = pd.concat([dataset, genres_list], axis=1)\n",
    "\n",
    "# botar la columna original 'genres'\n",
    "dataset.drop(columns=['genres'], inplace=True)\n",
    "\n",
    "#director_professions: \n",
    "#Es mejor convertir los profesiones faltantes a NaN (No es un número)\n",
    "dataset['director_professions'].replace('-', np.nan, inplace=True)\n",
    "#Varias profesiones separadas por coma\n",
    "#De manera similar a los géneros, podemos usar la codificación one-hot para \n",
    "#convertir las profesiones de director en columnas binarias separadas para cada profesión.\n",
    "professions_list = dataset['director_professions'].str.get_dummies(sep=',')\n",
    "dataset = pd.concat([dataset, professions_list], axis=1)\n",
    "\n",
    "# botar la columna original 'director_professions'\n",
    "dataset.drop(columns=['director_professions'], inplace=True)\n",
    "\n",
    "#director:birthYear: valores faltantes como '-'\n",
    "#Es mejor convertir los años de nacimiento faltantes a NaN (No es un número) para que\n",
    "#se manejen correctamente durante el procesamiento de datos.\n",
    "dataset['director_birthYear'].replace(r'\\N', '-1', inplace=True)\n",
    "dataset['director_birthYear'].replace('-', -1, inplace=True)\n",
    "dataset['director_birthYear'] = dataset['director_birthYear'].astype(int)\n",
    "\n",
    "# director:deathYear: valores faltantes como '-' y 'alive' si no está muerto\n",
    "#Podemos convertir los valores 'vivos' a NaN y reemplazar el '-' con NaN también.\n",
    "# Convertir 'alive' a NaN \n",
    "dataset['director_deathYear'].replace('alive', -1, inplace=True)\n",
    "# Convertir '-' a NaN \n",
    "dataset['director_deathYear'].replace('-', -1, inplace=True)\n",
    "dataset['director_deathYear'] = dataset['director_deathYear'].astype(int)\n",
    "\n",
    "# director_name\n",
    "# Por el momento boto el nombre del director \n",
    "dataset.drop(columns=['director_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['runtime_minutes', 'director_birthYear', 'director_deathYear',\n",
       "       'movie_averageRating', 'movie_numerOfVotes', 'approval_Index',\n",
       "       'Production budget $', 'Domestic gross $', 'Worldwide gross $',\n",
       "       'production_year', 'production_month', 'production_day', 'Action',\n",
       "       'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
       "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
       "       'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi', 'Sport', 'Thriller',\n",
       "       'War', 'Western', 'actor', 'actress', 'animation_department',\n",
       "       'art_department', 'art_director', 'assistant_director',\n",
       "       'camera_department', 'casting_department', 'casting_director',\n",
       "       'cinematographer', 'composer', 'costume_designer', 'director', 'editor',\n",
       "       'editorial_department', 'executive', 'location_management',\n",
       "       'make_up_department', 'miscellaneous', 'music_artist',\n",
       "       'music_department', 'producer', 'production_designer',\n",
       "       'production_manager', 'script_department', 'sound_department',\n",
       "       'soundtrack', 'special_effects', 'stunts', 'transportation_department',\n",
       "       'visual_effects', 'writer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('int32'), dtype('int32'), dtype('int32'), dtype('float64'),\n",
       "       dtype('float64'), dtype('float64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64'), dtype('int64'),\n",
       "       dtype('int64'), dtype('int64'), dtype('int64')], dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dtypes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runtime_minutes                 192.0\n",
       "director_birthYear             1954.0\n",
       "director_deathYear               -1.0\n",
       "movie_averageRating               7.8\n",
       "movie_numerOfVotes           277543.0\n",
       "                               ...   \n",
       "special_effects                   0.0\n",
       "stunts                            0.0\n",
       "transportation_department         0.0\n",
       "visual_effects                    0.0\n",
       "writer                            1.0\n",
       "Name: Avatar: The Way of Water, Length: 67, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer características y meta \n",
    "y = dataset['Worldwide gross $']\n",
    "X = dataset.drop(columns=['Worldwide gross $'])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identificar columnas numericas para estandarizar (excluyendo no-numericas)\n",
    "numeric_columns = X_train.select_dtypes(include=['float64', 'int64','int32']).columns\n",
    "\n",
    "# Standardize the numeric input features\n",
    "scaler = StandardScaler()\n",
    "X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
    "X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 51541780805451776.0000 - mae: 111766544.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766552.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766552.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541797985320960.0000 - mae: 111766544.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541785100419072.0000 - mae: 111766504.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 6/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541802280288256.0000 - mae: 111766520.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541780805451776.0000 - mae: 111766536.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541780805451776.0000 - mae: 111766520.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541759330615296.0000 - mae: 111766560.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541785100419072.0000 - mae: 111766536.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541785100419072.0000 - mae: 111766512.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 12/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541780805451776.0000 - mae: 111766552.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541785100419072.0000 - mae: 111766520.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 14/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541767920549888.0000 - mae: 111766552.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 15/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541789395386368.0000 - mae: 111766552.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 16/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766560.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 17/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541789395386368.0000 - mae: 111766536.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 18/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541797985320960.0000 - mae: 111766544.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 19/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541785100419072.0000 - mae: 111766560.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541780805451776.0000 - mae: 111766504.0000 - val_loss: 61200135756972032.0000 - val_mae: 127529576.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22392cd0a50>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Red Neuronal con Activación Sigmoidal y Regularización L1:\n",
    "model_1 = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(16, activation='sigmoid'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Agregar regularización L1 a todas las capas ocultas\n",
    "model_1.add(layers.Dense(16, activation='sigmoid', kernel_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "# Compilar el modelo\n",
    "model_1.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model_1.fit(X_train, y_train, epochs=20, batch_size=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "117/117 [==============================] - 1s 3ms/step - loss: 51541729265844224.0000 - mae: 111766440.0000 - val_loss: 61199826519326720.0000 - val_mae: 127529016.0000\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51539311199256576.0000 - mae: 111762128.0000 - val_loss: 61191558707281920.0000 - val_mae: 127515824.0000\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51520443407925248.0000 - mae: 111731072.0000 - val_loss: 61147513817661440.0000 - val_mae: 127449240.0000\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51449108296105984.0000 - mae: 111622600.0000 - val_loss: 61011341879541760.0000 - val_mae: 127247424.0000\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51273353939386368.0000 - mae: 111358584.0000 - val_loss: 60737082447888384.0000 - val_mae: 126841776.0000\n",
      "Epoch 6/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 50959091182338048.0000 - mae: 110881944.0000 - val_loss: 60245540620730368.0000 - val_mae: 126118096.0000\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 50416327575207936.0000 - mae: 110070104.0000 - val_loss: 59448953036341248.0000 - val_mae: 124941960.0000\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 49597461995454464.0000 - mae: 108815336.0000 - val_loss: 58286240964804608.0000 - val_mae: 123213200.0000\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 48411260747776000.0000 - mae: 107030840.0000 - val_loss: 56685588257964032.0000 - val_mae: 120849472.0000\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 46877399077355520.0000 - mae: 104756616.0000 - val_loss: 54638976211877888.0000 - val_mae: 117827456.0000\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 45006726071582720.0000 - mae: 101868016.0000 - val_loss: 52153512997421056.0000 - val_mae: 114177600.0000\n",
      "Epoch 12/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 42733983997362176.0000 - mae: 98367544.0000 - val_loss: 49290148495491072.0000 - val_mae: 110055424.0000\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 40208246874570752.0000 - mae: 94656368.0000 - val_loss: 46072517911117824.0000 - val_mae: 105462832.0000\n",
      "Epoch 14/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 37242408747925504.0000 - mae: 90409696.0000 - val_loss: 42606165770633216.0000 - val_mae: 100615648.0000\n",
      "Epoch 15/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 33958330724515840.0000 - mae: 85893304.0000 - val_loss: 38977193283420160.0000 - val_mae: 95876656.0000\n",
      "Epoch 16/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 31108080905224192.0000 - mae: 81781232.0000 - val_loss: 35426477247823872.0000 - val_mae: 91420960.0000\n",
      "Epoch 17/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 28440947016597504.0000 - mae: 78755696.0000 - val_loss: 32172257837056000.0000 - val_mae: 87489856.0000\n",
      "Epoch 18/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 25495595883954176.0000 - mae: 75300856.0000 - val_loss: 29128844011110400.0000 - val_mae: 84099536.0000\n",
      "Epoch 19/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 23365169698570240.0000 - mae: 72593168.0000 - val_loss: 26492021854175232.0000 - val_mae: 81367720.0000\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 21246631982661632.0000 - mae: 71043936.0000 - val_loss: 24339798709764096.0000 - val_mae: 79163504.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22393204e10>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Red Neuronal con Activación ReLU y Regularización Dropout:\n",
    "model_2 = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model_2.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model_2.fit(X_train, y_train, epochs=20, batch_size=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "117/117 [==============================] - 1s 4ms/step - loss: 51541785100419072.0000 - mae: 111766560.0000 - val_loss: 61200131462004736.0000 - val_mae: 127529576.0000\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766552.0000 - val_loss: 61200131462004736.0000 - val_mae: 127529576.0000\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541772215517184.0000 - mae: 111766536.0000 - val_loss: 61200131462004736.0000 - val_mae: 127529576.0000\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541772215517184.0000 - mae: 111766520.0000 - val_loss: 61200131462004736.0000 - val_mae: 127529568.0000\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541785100419072.0000 - mae: 111766512.0000 - val_loss: 61200131462004736.0000 - val_mae: 127529560.0000\n",
      "Epoch 6/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766512.0000 - val_loss: 61200131462004736.0000 - val_mae: 127529560.0000\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766480.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529560.0000\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541767920549888.0000 - mae: 111766496.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529560.0000\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766496.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529552.0000\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541789395386368.0000 - mae: 111766496.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529552.0000\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766480.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529552.0000\n",
      "Epoch 12/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541767920549888.0000 - mae: 111766504.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529536.0000\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541776510484480.0000 - mae: 111766512.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529528.0000\n",
      "Epoch 14/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541780805451776.0000 - mae: 111766504.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529528.0000\n",
      "Epoch 15/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541759330615296.0000 - mae: 111766488.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529528.0000\n",
      "Epoch 16/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541750740680704.0000 - mae: 111766488.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529520.0000\n",
      "Epoch 17/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541785100419072.0000 - mae: 111766448.0000 - val_loss: 61200118577102848.0000 - val_mae: 127529512.0000\n",
      "Epoch 18/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541759330615296.0000 - mae: 111766496.0000 - val_loss: 61200114282135552.0000 - val_mae: 127529512.0000\n",
      "Epoch 19/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541767920549888.0000 - mae: 111766456.0000 - val_loss: 61200114282135552.0000 - val_mae: 127529504.0000\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - 0s 2ms/step - loss: 51541759330615296.0000 - mae: 111766496.0000 - val_loss: 61200105692200960.0000 - val_mae: 127529504.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22398419b10>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Red Neuronal con Activación Tangente Hiperbólica (Tanh) y Regularización L2:\n",
    "model_3 = tf.keras.Sequential([\n",
    "    layers.Dense(256, activation='tanh', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(128, activation='tanh', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(64, activation='tanh', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model_3.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model_3.fit(X_train, y_train, epochs=20, batch_size=30, validation_data=(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Obtenidos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferencia de rendimiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal Optima"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
