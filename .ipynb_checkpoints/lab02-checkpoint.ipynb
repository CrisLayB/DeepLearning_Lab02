{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad del Valle de Guatemala\n",
    "\n",
    "Facultad de Ingeniería\n",
    "\n",
    "Departamento de Ciencias de la Computación\n",
    "\n",
    "Deep Learning y Sistemas Inteligentes - Sección 20\n",
    "\n",
    "Grupo 12:\n",
    "\n",
    "    Cristian Laynez\n",
    "    Jeyner Arango"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo de la Red"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación de Redes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paquetes a utilizar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# Cargar la base de datos\n",
    "dataset = pd.read_csv('movie_statistic_dataset.csv')\n",
    "\n",
    "# eliminar las filas con valores faltantes en la columna de destino\n",
    "dataset = dataset.dropna(subset=['Worldwide gross $'])\n",
    "\n",
    "# Extraer características y meta \n",
    "X = dataset.drop(columns=['Worldwide gross $'])\n",
    "y = dataset['Worldwide gross $']\n",
    "\n",
    "#director_name\n",
    "#Es mejor convertir los directores faltantes a NaN (No es un número)\n",
    "dataset['director_name'].replace('-', np.nan, inplace=True)\n",
    "\n",
    "# Convertir columnas categóricas a numericas usando codificación one-hot\n",
    "#X = pd.get_dummies(X, columns=['movie_title', 'genres', 'director_name', 'director_professions'])\n",
    "\n",
    "#production_date: AAAA-MM-DD\n",
    "#Como el campo representa una fecha, es mejor transformarlo en características separadas de\n",
    "#año, mes y día. De esta manera, la red neuronal puede capturar mejor los patrones temporales.\n",
    "dataset['production_year'] = pd.to_datetime(dataset['production_date']).dt.year\n",
    "dataset['production_month'] = pd.to_datetime(dataset['production_date']).dt.month\n",
    "dataset['production_day'] = pd.to_datetime(dataset['production_date']).dt.day\n",
    "\n",
    "# botar la columnar original 'production_date' \n",
    "dataset.drop(columns=['production_date'], inplace=True)\n",
    "\n",
    "#genres: varios géneros separados por comas\n",
    "#Podemos usar la codificación one-hot para convertir \n",
    "#los géneros en columnas binarias separadas para cada género.\n",
    "# Convertir genres a columnas binarias utilizando one-hot encoding\n",
    "dataset['genres'].replace(r'\\N', '', inplace=True)\n",
    "genres_list = dataset['genres'].str.get_dummies(sep=',')\n",
    "dataset = pd.concat([dataset, genres_list], axis=1)\n",
    "\n",
    "# botar la columna original 'genres'\n",
    "dataset.drop(columns=['genres'], inplace=True)\n",
    "\n",
    "#director_professions: varias profesiones separadas por coma\n",
    "#De manera similar a los géneros, podemos usar la codificación one-hot para \n",
    "#convertir las profesiones de director en columnas binarias separadas para cada profesión.\n",
    "professions_list = dataset['director_professions'].str.get_dummies(sep=',')\n",
    "dataset = pd.concat([dataset, professions_list], axis=1)\n",
    "\n",
    "# botar la columna original 'director_professions'\n",
    "dataset.drop(columns=['director_professions'], inplace=True)\n",
    "\n",
    "#director:birthYear: valores faltantes como '-'\n",
    "#Es mejor convertir los años de nacimiento faltantes a NaN (No es un número) para que\n",
    "#se manejen correctamente durante el procesamiento de datos.\n",
    "dataset['director_birthYear'].replace('-', np.nan, inplace=True)\n",
    "\n",
    "# director:deathYear: valores faltantes como '-' y 'alive' si no está muerto\n",
    "#Podemos convertir los valores 'vivos' a NaN y reemplazar el '-' con NaN también.\n",
    "# Convertir 'alive' a NaN \n",
    "dataset['director_deathYear'].replace('alive', np.nan, inplace=True)\n",
    "# Convertir '-' a NaN \n",
    "dataset['director_deathYear'].replace('-', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_title', 'runtime_minutes', 'director_name', 'director_birthYear',\n",
       "       'director_deathYear', 'movie_averageRating', 'movie_numerOfVotes',\n",
       "       'approval_Index', 'Production budget $', 'Domestic gross $',\n",
       "       'Worldwide gross $', 'production_year', 'production_month',\n",
       "       'production_day', 'Action', 'Adventure', 'Animation', 'Biography',\n",
       "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy',\n",
       "       'Film-Noir', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'News',\n",
       "       'Romance', 'Sci-Fi', 'Sport', 'Thriller', 'War', 'Western', '-',\n",
       "       'actor', 'actress', 'animation_department', 'art_department',\n",
       "       'art_director', 'assistant_director', 'camera_department',\n",
       "       'casting_department', 'casting_director', 'cinematographer', 'composer',\n",
       "       'costume_designer', 'director', 'editor', 'editorial_department',\n",
       "       'executive', 'location_management', 'make_up_department',\n",
       "       'miscellaneous', 'music_artist', 'music_department', 'producer',\n",
       "       'production_designer', 'production_manager', 'script_department',\n",
       "       'sound_department', 'soundtrack', 'special_effects', 'stunts',\n",
       "       'transportation_department', 'visual_effects', 'writer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_title                  Avatar: The Way of Water\n",
       "runtime_minutes                                 192.0\n",
       "director_name                           James Cameron\n",
       "director_birthYear                               1954\n",
       "director_deathYear                                NaN\n",
       "                                       ...           \n",
       "special_effects                                     0\n",
       "stunts                                              0\n",
       "transportation_department                           0\n",
       "visual_effects                                      0\n",
       "writer                                              1\n",
       "Name: 0, Length: 70, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Estandarizar las características de entrada\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Red Neuronal con Activación Sigmoidal y Regularización L1:\n",
    "model_1 = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(16, activation='sigmoid'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Agregar regularización L1 a todas las capas ocultas\n",
    "model_1.add(layers.Dense(16, activation='sigmoid', kernel_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "# Compilar el modelo\n",
    "model_1.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model_1.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Red Neuronal con Activación ReLU y Regularización Dropout:\n",
    "model_2 = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model_2.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model_2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Red Neuronal con Activación Tangente Hiperbólica (Tanh) y Regularización L2:\n",
    "model_3 = tf.keras.Sequential([\n",
    "    layers.Dense(256, activation='tanh', kernel_regularizer=regularizers.l2(0.01), input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(128, activation='tanh', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(64, activation='tanh', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(32, activation='tanh', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model_3.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model_3.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Obtenidos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferencia de rendimiento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Red Neuronal Optima"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
